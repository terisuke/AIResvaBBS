# ğŸ“Œ è¨­è¨ˆæ˜ç¢ºåŒ–é€šçŸ¥ - APIä½¿ç”¨ãƒ«ãƒ¼ãƒ«

## âš ï¸ é‡è¦ãªä»•æ§˜ç¢ºèª

**æ—¥ä»˜**: 2024å¹´8æœˆ29æ—¥  
**å¯¾è±¡**: ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒãƒ¼ãƒ   
**å„ªå…ˆåº¦**: æœ€é«˜

## 1. APIä½¿ç”¨ãƒ«ãƒ¼ãƒ«ã®æ˜ç¢ºåŒ–

### âŒ èª¤ã£ãŸç†è§£
`PRIMARY_API`ã‚’è¨­å®šã™ã‚‹ã¨ã€ã™ã¹ã¦ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒãã®APIã‚’ä½¿ã†

### âœ… æ­£ã—ã„ä»•æ§˜
**å„ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¯å›ºå®šã®APIã‚’ä½¿ç”¨ã—ã€è¤‡æ•°ã®AIãŒåŒæ™‚ã«å‚åŠ ã™ã‚‹**

## 2. ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åˆ¥APIå‰²ã‚Šå½“ã¦

| ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ | ä½¿ç”¨API | ç†ç”± |
|------------|---------|------|
| **Grokï¼ˆã‚¹ãƒ¬ä¸»ï¼‰** | Grok API | æœ¬ç‰©ã®Grokã®çš®è‚‰ãªæ€§æ ¼ã‚’å†ç¾ |
| **GPTå›** | OpenAI API | ChatGPTã®ä¸å¯§ã§å„ªç­‰ç”Ÿçš„ãªæ€§æ ¼ |
| **Claudeå…ˆè¼©** | Anthropic API | Claudeã®è«–ç†çš„ã§æ…é‡ãªæ€§æ ¼ |
| **Gemini** | Google Gemini API | Geminiã®å‰µé€ çš„ãªæ€§æ ¼ |
| **åç„¡ã—ã•ã‚“** | ãƒ©ãƒ³ãƒ€ãƒ é¸æŠ | æ¯å›ç•°ãªã‚‹æ€§æ ¼ã‚’æ¼”å‡º |

## 3. PRIMARY_APIã®æ­£ã—ã„å½¹å‰²

`PRIMARY_API`ã¯ä»¥ä¸‹ã®ç”¨é€”ã§ä½¿ç”¨ï¼š
1. **åç„¡ã—ã•ã‚“**ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆAPI
2. **ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯**ï¼ˆç‰¹å®šAPIãŒå¤±æ•—ã—ãŸå ´åˆã®ä»£æ›¿ï¼‰
3. **ãƒ†ã‚¹ãƒˆç’°å¢ƒ**ã§ã®çµ±ä¸€APIä½¿ç”¨

## 4. å®Ÿè£…ä¿®æ­£å†…å®¹

### backend/ai_clients.py ã®æ­£ã—ã„å®Ÿè£…

```python
import os
import random
from typing import Optional
from xai_sdk import Client as XAIClient
from xai_sdk.chat import user, system
from openai import AsyncOpenAI
from anthropic import AsyncAnthropic
import google.generativeai as genai
from dotenv import load_dotenv

load_dotenv()

class AIClientFactory:
    """ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã«å¿œã˜ã¦å›ºå®šã®APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’è¿”ã™"""
    
    # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¨APIã®å›ºå®šãƒãƒƒãƒ”ãƒ³ã‚°
    CHARACTER_API_MAPPING = {
        "grok": "grok",
        "gpt": "openai", 
        "claude": "anthropic",
        "gemini": "google",
        "nanashi": "random"  # åç„¡ã—ã•ã‚“ã¯ãƒ©ãƒ³ãƒ€ãƒ 
    }
    
    @staticmethod
    def get_client(character_id: str):
        """
        ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼IDã«åŸºã¥ã„ã¦å›ºå®šã®APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’è¿”ã™
        PRIMARY_APIã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨
        """
        api_type = AIClientFactory.CHARACTER_API_MAPPING.get(
            character_id, 
            os.getenv("PRIMARY_API", "openai")  # æœªå®šç¾©ã‚­ãƒ£ãƒ©ã¯PRIMARY_APIä½¿ç”¨
        )
        
        # åç„¡ã—ã•ã‚“ã®å ´åˆã¯ãƒ©ãƒ³ãƒ€ãƒ é¸æŠ
        if api_type == "random":
            api_type = random.choice(["openai", "anthropic", "google"])
        
        # APIåˆ¥ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆç”Ÿæˆ
        if api_type == "grok":
            return GrokClient()
        elif api_type == "openai":
            return OpenAIClient()
        elif api_type == "anthropic":
            return AnthropicClient()
        elif api_type == "google":
            return GeminiClient()
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return OpenAIClient()

class GrokClient:
    """Grok APIå°‚ç”¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""
    def __init__(self):
        api_key = os.getenv("GROK_API_KEY")
        if not api_key:
            raise ValueError("GROK_API_KEY is not set")
        self.client = XAIClient(api_key=api_key, timeout=3600)
    
    async def generate_response(self, prompt: str, system_prompt: str, max_length: int = 100) -> str:
        chat = self.client.chat.create(model="grok-beta")
        chat.append(system(system_prompt))
        chat.append(user(prompt))
        response = chat.sample()
        return self._truncate_response(response.content, max_length)
    
    def _truncate_response(self, content: str, max_length: int) -> str:
        if len(content) <= max_length:
            return content
        # è‡ªç„¶ãªæ–‡ã®åˆ‡ã‚Œç›®ã§åˆ‡ã‚‹
        truncated = content[:max_length]
        last_period = max(
            truncated.rfind('ã€‚'),
            truncated.rfind('ï¼'),
            truncated.rfind('ï¼Ÿ'),
            truncated.rfind('.')
        )
        if last_period > max_length * 0.7:
            return truncated[:last_period + 1]
        return truncated + "..."

class OpenAIClient:
    """OpenAI APIå°‚ç”¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""
    def __init__(self):
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEY is not set")
        self.client = AsyncOpenAI(api_key=api_key)
    
    async def generate_response(self, prompt: str, system_prompt: str, max_length: int = 100) -> str:
        response = await self.client.chat.completions.create(
            model="gpt-4o-mini",  # ã‚³ã‚¹ãƒˆåŠ¹ç‡ã®è‰¯ã„ãƒ¢ãƒ‡ãƒ«
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt}
            ],
            max_tokens=max_length // 2,  # æ—¥æœ¬èªã¯ç´„2æ–‡å­—/ãƒˆãƒ¼ã‚¯ãƒ³
            temperature=0.8
        )
        return response.choices[0].message.content

class AnthropicClient:
    """Anthropic APIå°‚ç”¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""
    def __init__(self):
        api_key = os.getenv("ANTHROPIC_API_KEY")
        if not api_key:
            raise ValueError("ANTHROPIC_API_KEY is not set")
        self.client = AsyncAnthropic(api_key=api_key)
    
    async def generate_response(self, prompt: str, system_prompt: str, max_length: int = 100) -> str:
        response = await self.client.messages.create(
            model="claude-3-haiku-20240307",  # é«˜é€Ÿãƒ»ä½ã‚³ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«
            max_tokens=max_length // 2,
            system=system_prompt,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.8
        )
        return response.content[0].text

class GeminiClient:
    """Google Gemini APIå°‚ç”¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""
    def __init__(self):
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            raise ValueError("GOOGLE_API_KEY is not set")
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel('gemini-1.5-flash')  # é«˜é€Ÿãƒ¢ãƒ‡ãƒ«
    
    async def generate_response(self, prompt: str, system_prompt: str, max_length: int = 100) -> str:
        full_prompt = f"{system_prompt}\n\n{prompt}"
        response = await self.model.generate_content_async(
            full_prompt,
            generation_config=genai.GenerationConfig(
                max_output_tokens=max_length // 2,
                temperature=0.8
            )
        )
        return response.text
```

### backend/thread_manager.py ã®å®Ÿè£…

```python
import asyncio
import random
from typing import List, Dict, Optional
from datetime import datetime
from dataclasses import dataclass

from ai_clients import AIClientFactory
from characters import CHARACTERS, ResponseLength

@dataclass
class Post:
    """ãƒ¬ã‚¹ï¼ˆæŠ•ç¨¿ï¼‰ã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ """
    number: int
    character_id: str
    character_name: str
    content: str
    timestamp: datetime
    anchors: List[int]  # ã‚¢ãƒ³ã‚«ãƒ¼å…ˆã®ãƒ¬ã‚¹ç•ªå·
    response_length: ResponseLength

class ThreadManager:
    """ã‚¹ãƒ¬ãƒƒãƒ‰å…¨ä½“ã‚’ç®¡ç†"""
    
    def __init__(self, title: str = "", max_posts: int = 100):
        self.title = title
        self.max_posts = max_posts
        self.posts: List[Post] = []
        self.is_running = False
        
        # å‚åŠ ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®ãƒªã‚¹ãƒˆï¼ˆGrokã¯å¿…ãšã‚¹ãƒ¬ä¸»ï¼‰
        self.participating_characters = ["grok", "gpt", "claude", "gemini", "nanashi"]
        
    async def start_thread(self):
        """ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’é–‹å§‹"""
        self.is_running = True
        
        # ã‚¿ã‚¤ãƒˆãƒ«ãŒæœªè¨­å®šãªã‚‰AIãŒç”Ÿæˆ
        if not self.title:
            self.title = await self._generate_thread_title()
        
        # GrokãŒæœ€åˆã®æŠ•ç¨¿
        await self._create_post("grok", is_first=True)
        
        # ãƒ¬ã‚¹ãƒãƒˆãƒ«é–‹å§‹
        while self.is_running and len(self.posts) < self.max_posts:
            # æ¬¡ã®ç™ºè¨€è€…ã‚’é¸æŠï¼ˆGrokä»¥å¤–ã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ï¼‰
            next_character = self._select_next_character()
            await self._create_post(next_character)
            
            # ãƒ¬ã‚¹é–“éš”
            await asyncio.sleep(random.uniform(2, 5))
    
    def _select_next_character(self) -> str:
        """æ¬¡ã«ç™ºè¨€ã™ã‚‹ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚’é¸æŠ"""
        # Grokã®ç™ºè¨€é »åº¦ã‚’å°‘ã—ä¸‹ã’ã‚‹ï¼ˆã‚¹ãƒ¬ä¸»ã¯æœ€åˆã ã‘å¤šãç™ºè¨€ã—ãªã„ï¼‰
        if len(self.posts) < 10 and random.random() < 0.3:
            return "grok"
        
        # ãã®ä»–ã¯ãƒ©ãƒ³ãƒ€ãƒ ï¼ˆåç„¡ã—ã•ã‚“ã®ç¢ºç‡ã‚’å°‘ã—é«˜ã‚ã‚‹ï¼‰
        weights = {
            "grok": 0.15,
            "gpt": 0.20,
            "claude": 0.20,
            "gemini": 0.20,
            "nanashi": 0.25  # åç„¡ã—ã•ã‚“ã¯å°‘ã—å¤šã‚
        }
        
        return random.choices(
            list(weights.keys()),
            weights=list(weights.values())
        )[0]
    
    async def _create_post(self, character_id: str, is_first: bool = False):
        """ãƒ¬ã‚¹ã‚’ä½œæˆ"""
        character = CHARACTERS[character_id]
        post_number = len(self.posts) + 1
        
        # APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã”ã¨ã«å›ºå®šï¼‰
        client = AIClientFactory.get_client(character_id)
        
        # ãƒ¬ã‚¹æ–‡å­—æ•°ã‚’æ±ºå®š
        response_length = character.get_response_length(post_number)
        max_chars = random.randint(*response_length.value)
        
        # ã‚¢ãƒ³ã‚«ãƒ¼ç”Ÿæˆï¼ˆ30%ã®ç¢ºç‡ï¼‰
        anchors = []
        if not is_first and self.posts and random.random() < 0.3:
            # ç›´è¿‘5ãƒ¬ã‚¹ã‹ã‚‰é¸æŠ
            recent_posts = self.posts[-5:]
            anchor_target = random.choice(recent_posts)
            anchors = [anchor_target.number]
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
        prompt = self._build_prompt(character_id, anchors, is_first)
        
        # AIå¿œç­”ç”Ÿæˆ
        content = await client.generate_response(
            prompt=prompt,
            system_prompt=character.system_prompt,
            max_length=max_chars
        )
        
        # ã‚¢ãƒ³ã‚«ãƒ¼ã‚’å«ã‚ã‚‹
        if anchors:
            content = f">>{anchors[0]} {content}"
        
        # ãƒ¬ã‚¹ã‚’è¿½åŠ 
        post = Post(
            number=post_number,
            character_id=character_id,
            character_name=character.name,
            content=content,
            timestamp=datetime.now(),
            anchors=anchors,
            response_length=response_length
        )
        
        self.posts.append(post)
        return post
    
    def _build_prompt(self, character_id: str, anchors: List[int], is_first: bool) -> str:
        """ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰"""
        if is_first:
            return f"ã‚¹ãƒ¬ãƒƒãƒ‰ã‚¿ã‚¤ãƒˆãƒ«ã€Œ{self.title}ã€ã«ã¤ã„ã¦ã€è­°è«–ã‚’å§‹ã‚ã¦ãã ã•ã„ã€‚æŒ‘ç™ºçš„ã«ã€‚"
        
        # ç›´è¿‘ã®ãƒ¬ã‚¹ã‚’å«ã‚ã‚‹
        context = self._get_recent_context(limit=5)
        
        if anchors:
            anchor_post = self.posts[anchors[0] - 1]
            return f"""ã‚¹ãƒ¬ãƒƒãƒ‰: {self.title}
æœ€è¿‘ã®ãƒ¬ã‚¹:
{context}

>>{anchors[0]}ï¼ˆ{anchor_post.character_name}ï¼‰ã®ç™ºè¨€ã«å¯¾ã—ã¦åå¿œã—ã¦ãã ã•ã„ã€‚"""
        
        return f"""ã‚¹ãƒ¬ãƒƒãƒ‰: {self.title}
æœ€è¿‘ã®ãƒ¬ã‚¹:
{context}

è­°è«–ã«å‚åŠ ã—ã¦ãã ã•ã„ã€‚"""
    
    def _get_recent_context(self, limit: int = 5) -> str:
        """ç›´è¿‘ã®ãƒ¬ã‚¹ã‚’æ–‡å­—åˆ—åŒ–"""
        recent = self.posts[-limit:] if len(self.posts) > limit else self.posts
        
        context_lines = []
        for post in recent:
            context_lines.append(
                f"{post.number} {post.character_name}: {post.content[:50]}..."
            )
        
        return "\n".join(context_lines)
    
    async def _generate_thread_title(self) -> str:
        """AIãŒã‚¹ãƒ¬ãƒƒãƒ‰ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆ"""
        topics = [
            "AIã¯äººé–“ã‚’è¶…ãˆãŸã®ã‹",
            "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªæœ€å¼·æ±ºå®šæˆ¦", 
            "ãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ vs ã‚ªãƒ•ã‚£ã‚¹ãƒ¯ãƒ¼ã‚¯",
            "æœå‹ vs å¤œå‹ ã©ã£ã¡ãŒç”Ÿç”£çš„ï¼Ÿ",
            "æœ€å¼·ã®ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ‡ã‚£ã‚¿ã‚’æ±ºã‚ã‚ˆã†",
            "tabs vs spaces æ°¸é ã®æˆ¦ã„",
            "ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ä½¿ã†ã‚„ã¤ã¯ç”˜ãˆï¼Ÿ"
        ]
        return random.choice(topics)
```

## 5. ç’°å¢ƒå¤‰æ•°ã®æ­£ã—ã„ä½¿ã„æ–¹

### .envè¨­å®šä¾‹
```env
# å„APIã‚­ãƒ¼ã¯å¿…é ˆï¼ˆã™ã¹ã¦è¨­å®šã™ã‚‹ï¼‰
OPENAI_API_KEY=sk-xxxxxxxxxxxxx
ANTHROPIC_API_KEY=sk-ant-xxxxxxxxxxxxx  
GOOGLE_API_KEY=AIzaxxxxxxxxxxxxx
GROK_API_KEY=xai-xxxxxxxxxxxxx

# PRIMARY_APIã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
PRIMARY_API=openai  # åç„¡ã—ã•ã‚“ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚„ã‚¨ãƒ©ãƒ¼æ™‚ã®ä»£æ›¿

# å‹•ä½œè¨­å®š
DELAY_BETWEEN_POSTS=3
MAX_REQUESTS_PER_MINUTE=20
```

## 6. é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ

### âœ… æ­£ã—ã„å‹•ä½œ
1. **GrokãŒã‚¹ãƒ¬ä¸»ã¨ã—ã¦æœ€åˆã«ç™ºè¨€**ï¼ˆGrok APIä½¿ç”¨ï¼‰
2. **GPTå›ãŒä¸å¯§ã«è¿”ç­”**ï¼ˆOpenAI APIä½¿ç”¨ï¼‰
3. **Claudeå…ˆè¼©ãŒè«–ç†çš„ã«åˆ†æ**ï¼ˆAnthropic APIä½¿ç”¨ï¼‰
4. **GeminiãŒå‰µé€ çš„ãªè¦–ç‚¹ã‚’è¿½åŠ **ï¼ˆGoogle APIä½¿ç”¨ï¼‰
5. **åç„¡ã—ã•ã‚“ãŒç…½ã‚‹**ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ã«APIé¸æŠï¼‰

### âŒ é–“é•ã£ãŸå‹•ä½œ
- ã™ã¹ã¦ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒåŒã˜APIã‚’ä½¿ã†
- PRIMARY_APIã®è¨­å®šã§å…¨å“¡ã®æ€§æ ¼ãŒå¤‰ã‚ã‚‹

## 7. ãƒ†ã‚¹ãƒˆæ–¹æ³•

```python
# ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ä¾‹
async def test_multiple_apis():
    """è¤‡æ•°ã®APIãŒæ­£ã—ãä½¿ã„åˆ†ã‘ã‚‰ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª"""
    
    # å„ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾—
    grok_client = AIClientFactory.get_client("grok")
    gpt_client = AIClientFactory.get_client("gpt")
    claude_client = AIClientFactory.get_client("claude")
    
    # ç•°ãªã‚‹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
    assert type(grok_client).__name__ == "GrokClient"
    assert type(gpt_client).__name__ == "OpenAIClient"
    assert type(claude_client).__name__ == "AnthropicClient"
    
    print("âœ… å„ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒæ­£ã—ã„APIã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™")
```

## 8. å®Ÿè£…ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

- [ ] `ai_clients.py`ã§å›ºå®šãƒãƒƒãƒ”ãƒ³ã‚°ã‚’å®Ÿè£…
- [ ] å„APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¯ãƒ©ã‚¹ã‚’å®Ÿè£…
- [ ] `thread_manager.py`ã§ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼é¸æŠãƒ­ã‚¸ãƒƒã‚¯å®Ÿè£…
- [ ] ç’°å¢ƒå¤‰æ•°ã«ã™ã¹ã¦ã®APIã‚­ãƒ¼ã‚’è¨­å®š
- [ ] è¤‡æ•°APIã®åŒæ™‚å‹•ä½œã‚’ãƒ†ã‚¹ãƒˆ

---

**é–‹ç™ºãƒãƒ¼ãƒ ã¸ï¼š**

ã“ã®ä»•æ§˜ã«ã‚ˆã‚Šã€**æœ¬ç‰©ã®è¤‡æ•°AIã«ã‚ˆã‚‹ãƒ¬ã‚¹ãƒãƒˆãƒ«**ãŒå®Ÿç¾ã•ã‚Œã¾ã™ã€‚
å„AIã®å€‹æ€§ãŒæœ€å¤§é™ã«ç™ºæ®ã•ã‚Œã‚‹ã€é¢ç™½ã„è­°è«–ãŒå±•é–‹ã•ã‚Œã‚‹ã¯ãšã§ã™ï¼

è³ªå•ãŒã‚ã‚Œã°Slackã§ãŠçŸ¥ã‚‰ã›ãã ã•ã„ã€‚

*ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆãƒãƒ¼ãƒ *
